{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb01b59",
   "metadata": {},
   "source": [
    "# RNN & Attention: HW\n",
    "\n",
    "Привет! Это твоё домашнее задание: сделать модель, которая может переводить тексты с немецкого языка в англиский. Для обучения будет использоваться датасет [wmt-14](https://huggingface.co/datasets/wmt14). Для проверки будет использоваться BLEU на тестовой выборке и 10 примеров перевода вашей модели. В этом ноутбуке есть скелет для обучения модели трансформера. Но вы можете пользоваться и RNN, если вы считаете что можете обучить её под эту задачу. Главное -- получить `submission.yaml`, используя нейросети.\n",
    "\n",
    "**!Внимание!** В этой домашней работе нельзя пользоваться библиотекой `transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98993f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import gc\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46f4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import einops\n",
    "import evaluate\n",
    "import math\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c75a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36734faf",
   "metadata": {},
   "source": [
    "# Данные\n",
    "\n",
    "В этой части подготовьте данные для обучения. Не забудьте добавить \"BOS\", \"EOS\" и \"UNK\" токены в ваши словари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17509c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt14 (/home/alex/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4325b13906e143b6aa21e8a17e8f7e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wmt14 = load_dataset(\"wmt14\", \"de-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387eb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def tokenize_pipeline(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return [token for token in tokens if token.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f5da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_en = (\n",
    "    [tokenize_pipeline(sentence[\"en\"]) for sentence in wmt14[\"train\"][\"translation\"]] +\n",
    "    [tokenize_pipeline(sentence[\"en\"]) for sentence in wmt14[\"validation\"][\"translation\"]] +\n",
    "    [tokenize_pipeline(sentence[\"en\"]) for sentence in wmt14[\"test\"][\"translation\"]]\n",
    ")\n",
    "\n",
    "tokenized_de = (\n",
    "    [tokenize_pipeline(sentence[\"de\"]) for sentence in wmt14[\"train\"][\"translation\"]] +\n",
    "    [tokenize_pipeline(sentence[\"de\"]) for sentence in wmt14[\"validation\"][\"translation\"]] +\n",
    "    [tokenize_pipeline(sentence[\"de\"]) for sentence in wmt14[\"test\"][\"translation\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65158fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokenized_en_words = {word for words in tokenized_en for word in words}\n",
    "all_tokenized_de_words = {word for words in tokenized_de for word in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c68eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words_to_ids = {word: idx + 16 for idx, word in enumerate(all_tokenized_en_words)}\n",
    "de_words_to_ids = {word: idx + 16 for idx, word in enumerate(all_tokenized_de_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06971faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62f002",
   "metadata": {},
   "source": [
    "### Определим класс датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ec39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, words_to_ids_en, words_to_ids_de, dataset, max_len=64):\n",
    "        \n",
    "        def tokenize_sentence(example):\n",
    "            return {\"tokens\": tokenizer(example)}\n",
    "        \n",
    "        def convert_word_to_ids_en(example):\n",
    "            return list(words_to_ids_en[token] for token in example['tokens'])\n",
    "        \n",
    "        def convert_word_to_ids_de(example):\n",
    "            return list(words_to_ids_de[token] for token in example['tokens'])\n",
    "        \n",
    "        dataset_en, dataset_de = [], []\n",
    "        \n",
    "        for item in dataset:\n",
    "            dataset_en.append(item['en'])\n",
    "            dataset_de.append(item['de'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        dataset_en = list(map(tokenize_sentence, dataset_en))\n",
    "        self.dataset_en = list(map(convert_word_to_ids_en, dataset_en))\n",
    "        \n",
    "        del words_to_ids_en\n",
    "        gc.collect()\n",
    "        \n",
    "        dataset_de = list(map(tokenize_sentence, dataset_de))\n",
    "        self.dataset_de = list(map(convert_word_to_ids_de, dataset_de))\n",
    "        \n",
    "        del words_to_ids_de\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_de)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokens_ids_en = self.dataset_en[index]\n",
    "        tokens_ids_de = self.dataset_de[index]\n",
    "        \n",
    "        \n",
    "        if len(tokens_ids_en) < max_len:\n",
    "            tokens_ids_en = [1] + tokens_ids_en + [2 for _ in range(max_len - len(tokens_ids_en))]\n",
    "            \n",
    "        if len(tokens_ids_de) < max_len:\n",
    "            tokens_ids_de = [1] + tokens_ids_de + [2 for _ in range(max_len - len(tokens_ids_de))]\n",
    "            \n",
    "            \n",
    "        return tokens_ids_de[:max_len], tokens_ids_en[:max_len]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa52d6",
   "metadata": {},
   "source": [
    "### Сохраним нужные нам словари"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3536ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with open('de_words_to_ids.pickle', 'wb') as output:\n",
    "# #     pickle.dump(de_words_to_ids, output)\n",
    "    \n",
    "# # with open('all_tokenized_de_words.pickle', 'wb') as output:\n",
    "# #     pickle.dump(all_tokenized_de_words, output)\n",
    "    \n",
    "# # with open('en_words_to_ids.pickle', 'wb') as output:\n",
    "# #     pickle.dump(en_words_to_ids, output)\n",
    "    \n",
    "    \n",
    "# # with open('all_tokenized_en_words.pickle', 'wb') as output:\n",
    "# #     pickle.dump(all_tokenized_en_words, output)\n",
    "\n",
    "with open('de_words_to_ids.pickle', 'rb') as output:\n",
    "    de_words_to_ids = pickle.load(output)\n",
    "    \n",
    "with open('all_tokenized_de_words.pickle', 'rb') as output:\n",
    "    all_tokenized_de_words = pickle.load(output)\n",
    "    \n",
    "with open('en_words_to_ids.pickle', 'rb') as output:\n",
    "    en_words_to_ids = pickle.load(output)\n",
    "    \n",
    "    \n",
    "with open('all_tokenized_en_words.pickle', 'rb') as output:\n",
    "    all_tokenized_en_words = pickle.load(output)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb13c53",
   "metadata": {},
   "source": [
    "### Создадим датасеты и сохраним экземпляры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = [item for item in wmt14['train']['translation']]\n",
    "train_dataset = TranslationDataset(tokenize_pipeline, en_words_to_ids, de_words_to_ids,\n",
    "                                   dataset_train) \n",
    "\n",
    "with open('train_dataset.pickle', 'wb') as output:\n",
    "    pickle.dump(train_dataset, output)\n",
    "\n",
    "validation_dataset = [item for item in wmt14['validation']['translation']]\n",
    "valid_dataset = TranslationDataset(tokenize_pipeline, en_words_to_ids, de_words_to_ids,\n",
    "                                   validation_dataset) \n",
    "\n",
    "with open('validation_dataset.pickle', 'wb') as output:\n",
    "    pickle.dump(valid_dataset, output)\n",
    "    \n",
    "    \n",
    "test_dataset = [item for item in wmt14['test']['translation']]\n",
    "test_dataset = TranslationDataset(tokenize_pipeline, en_words_to_ids, de_words_to_ids,\n",
    "                                   test_dataset) \n",
    "\n",
    "with open('test_dataset.pickle', 'wb') as output:\n",
    "    pickle.dump(test_dataset, output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0726d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset.pickle', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "with open('validation_dataset.pickle', 'rb') as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "    \n",
    "with open('test_dataset.pickle', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd2e8b",
   "metadata": {},
   "source": [
    "### Collate_fn и Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518d389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    x = torch.LongTensor([i[0] for i in batch])\n",
    "    y = torch.LongTensor([i[1] for i in batch])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b2620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=3, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=3, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b5439",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Сделайте модель, которая может в перевод. Для этой модели потребуется сделать `Encoder` и `Decoder`. Первый будет брать текст на немецком и отдавать информацию про него. Decoder будет брать информацию про немецкий текст и превращать его в английский."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если вам нужны дополнительные модули, такие как Attention или Transformer layer, то можете добавить их сюда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57070a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global params\n",
    "vocab_en_size, vocab_de_size = 732992 + 16, 1582945 + 16\n",
    "embadding__dim = 256\n",
    "device = 'cuda'\n",
    "num_heads = 4\n",
    "batch_size = 4\n",
    "# max_len = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95846299",
   "metadata": {},
   "source": [
    "Для слоев Encoder можете скопировать код из семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782bcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, 4*hid_dim)\n",
    "        self.fc_2 = nn.Linear(4*hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761df3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTransformerLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim: int, n_heads: int, dropout: float, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "        self.attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout,device)\n",
    "        self.mlp = MLP(hidden_dim, dropout)\n",
    "        self.out_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, inputs, mask):\n",
    "        \n",
    "        x, _ = self.attention(inputs, inputs, inputs) \n",
    "        \n",
    "        norm = self.layer_norm(inputs + self.dropout(x))\n",
    "        \n",
    "        x = self.mlp(norm) \n",
    "        x = self.out_norm(norm + x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39694725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTransformerLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim: int, n_heads: int, dropout: float, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.layer_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout, device)\n",
    "        self.out_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout,device)\n",
    "        self.mlp = MLP(hidden_dim, dropout)\n",
    "        self.middl_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "        self.out_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, encoder_layer_output, inputs_mask, enc_mask):\n",
    "        \n",
    "        x, _ = self.self_attention(inputs, inputs, inputs, inputs_mask)\n",
    "        \n",
    "        norm = self.layer_norm(inputs + x)\n",
    "        \n",
    "        x, attention = self.out_attention(norm, encoder_layer_output, encoder_layer_output, enc_mask)\n",
    "        \n",
    "        norm = self.middl_norm(norm + x)\n",
    "      \n",
    "        x = self.mlp(norm)\n",
    "        \n",
    "        out = self.out_norm(norm + x)\n",
    "        \n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c52343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, de_dictionary_size: int, hidden_dim: int, n_layer: int, \n",
    "                 n_heads: int, dropout: float, max_length: int, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = torch.nn.Embedding(de_dictionary_size, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "        self.transformer = torch.nn.ModuleList([EncoderTransformerLayer(hidden_dim, n_heads, dropout, device) \n",
    "                                                           for _ in range(n_layer)])\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "        \n",
    "    def forward(self, inputs, mask):\n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs_len = inputs.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, inputs_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "        x = (self.word_embedding(inputs)*self.scale)\n",
    "        x = x + self.pos_embedding(pos)\n",
    "\n",
    "        for layer in self.transformer:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cb8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, en_dictionary_size: int, hidden_dim: int, max_length: int, n_layers: int, \n",
    "                 n_heads: int, dropout: float, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = torch.nn.Embedding(en_dictionary_size, hidden_dim)\n",
    "        self.pos_embedding = torch.nn.Embedding(max_length, hidden_dim)\n",
    "        self.transformer = nn.ModuleList([DecoderTransformerLayer(hidden_dim, \n",
    "                                                  n_heads,  \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "        \n",
    "        self.lm_head = torch.nn.Linear(hidden_dim, en_dictionary_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, encoder_output, inputs_mask, enc_mask):\n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "        input_len = inputs.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, input_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        x = self.dropout(self.word_embedding(inputs)*self.scale) + self.pos_embedding(pos)\n",
    "        for layer in self.transformer:\n",
    "            x = layer(x, encoder_output, inputs_mask, enc_mask)\n",
    "        \n",
    "        x = self.lm_head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974e57b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "877d38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationModel(torch.nn.Module):\n",
    "    def __init__(self, de_dictionary_size: int, en_dictionary_size: int, hidden_dim: int, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        n_layer = 2\n",
    "        n_heads = 4\n",
    "        dropout = 0.12\n",
    "        max_length = max_len\n",
    "        self.encoder = Encoder(de_dictionary_size, hidden_dim, n_layer, n_heads, dropout, max_length, device)\n",
    "        self.decoder = Decoder(en_dictionary_size, hidden_dim, max_length, n_layer, n_heads, dropout, device)\n",
    "        self.idx = 2\n",
    "        \n",
    "    def make_src_mask(self, src, src_pad_idx):\n",
    "\n",
    "        src_mask = (src != src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg, trg_pad_idx):\n",
    "\n",
    "        trg_pad_mask = (trg != trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "\n",
    "        return trg_mask\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        original_ids, translation_ids = inputs\n",
    "        \n",
    "        original_mask = self.make_src_mask(original_ids, 2)\n",
    "        translation_mask = self.make_trg_mask(translation_ids, 2)\n",
    "        encoder_output = self.encoder(original_ids, original_mask)\n",
    "       \n",
    "        decoder_output = self.decoder(translation_ids, encoder_output, translation_mask, original_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c0fe8",
   "metadata": {},
   "source": [
    "Сделайте модель, оптимиизатор и лосс функцию. В нашем случае лосс функция будет проверять предсказанию токенов на каждой позиции -- по сути классификатор на каждую позицию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92e26944",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "lr = 0.001\n",
    "model = TranslationModel(vocab_de_size, vocab_en_size, 32, device).to(device)\n",
    "# model = torch.load('model_64_last.pth', torch.device('cpu'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d725bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98361264"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb792fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6999/1502929 [08:16<29:28:39, 14.10it/s, loss=tensor(1.1248, device='cuda:0', grad_fn=<NllLossBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# add Train Loop\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(train_dataloader)\n",
    "    for original_ids, translation_ids in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        original_ids = original_ids.to(device)\n",
    "        translation_ids = translation_ids.to(device)\n",
    "        \n",
    "        output = model((original_ids, translation_ids))\n",
    "        \n",
    "        \n",
    "        loss = criterion(output.view(-1, output.shape[-1]), translation_ids.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (original_ids, translation_ids) in enumerate(valid_dataloader):\n",
    "            original_ids = original_ids.to(device)\n",
    "            translation_ids = translation_ids.to(device)\n",
    "\n",
    "            output = model((original_ids, translation_ids))\n",
    "\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), translation_ids.view(-1))\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Epoch {epoch + 1} | Train Loss: {train_loss / len(train_dataloader):.4f} | Validation Loss: {valid_loss / len(valid_dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a382572",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf9af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_device(model, device):\n",
    "    model = model.to(device)\n",
    "    model.device = device\n",
    "    model.decoder.device = device\n",
    "    model.decoder.scale = model.decoder.scale.to(device)\n",
    "    \n",
    "    model.encoder.device = device\n",
    "    model.encoder.scale = model.decoder.scale.to(device)\n",
    "    model = model.to(device)\n",
    "#     for param in model.parameters():\n",
    "#         param.data = param.data.to(device)\n",
    "#         if param._grad is not None:\n",
    "#             param._grad = param._grad.to(device)\n",
    "            \n",
    "    for layer in model.encoder.transformer:\n",
    "        layer.attention.scale = layer.attention.scale.to(device)\n",
    "    \n",
    "    for layer in model.decoder.transformer:\n",
    "        layer.self_attention.scale = layer.self_attention.scale.to(device)\n",
    "        layer.out_attention.scale = layer.out_attention.scale.to(device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed7ecc",
   "metadata": {},
   "source": [
    "Чтобы получить перевод, надо сделать функцию для декодинга. Она будет брать предсказания токена на последней позиции и отдавать нужный токен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dab60d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_world = {val:key for key, val in en_words_to_ids.items()}\n",
    "id_to_world[1] = '[BOS]'\n",
    "id_to_world[2] = '[EOS]'\n",
    "\n",
    "def get_last_token_prediction(prefix, original, model, device='cpu', return_seq = False):\n",
    "        \n",
    "        if len(prefix) == len(original) + 1:\n",
    "            return '[EOS]'\n",
    "        \n",
    "        prefix = {\"tokens\": tokenize_pipeline(prefix)}\n",
    "        prefix = list(en_words_to_ids[token] for token in prefix['tokens'])\n",
    "        id_future = len(prefix)\n",
    "        \n",
    "        original = {\"tokens\": tokenize_pipeline(original)}\n",
    "     \n",
    "        original = list(de_words_to_ids[token] for token in original['tokens'])\n",
    "       \n",
    "        orig_len = len(original)\n",
    "        if len(prefix) < 25:\n",
    "            prefix = [1] + prefix + [2 for _ in range(max_len - len(prefix))]\n",
    "            \n",
    "        if len(original) < 25:\n",
    "            original = [1] + original + [2 for _ in range(max_len - len(original))]\n",
    "            \n",
    "            \n",
    "        original, prefix = torch.LongTensor(original[:max_len]), torch.LongTensor(prefix[:max_len])\n",
    "        original, prefix = original.unsqueeze(0), prefix.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model((original.to(device), prefix.to(device)))\n",
    "          \n",
    "        if return_seq:\n",
    "            index = torch.argmax(output, dim=2).tolist()[0][1:orig_len+1]\n",
    "            return [id_to_world[ind] for ind in index]\n",
    "        \n",
    "        preds = torch.argmax(output, dim=2)\n",
    "        return id_to_world[int(preds[0, id_future+1])]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87a7c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = model_to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d127b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally Every'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Guten Morgen!\"\n",
    "prefix = \"\"\n",
    "# device = 'cuda'\n",
    "get_last_token_prediction(prefix, original, model, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aff16f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President her \n"
     ]
    }
   ],
   "source": [
    "last_token_eos = False\n",
    "original = \"Guten Morgen!\"\n",
    "prefix = \"\"\n",
    "\n",
    "while not last_token_eos:\n",
    "    token = get_last_token_prediction(prefix, original, model)\n",
    "    prefix += token + ' '\n",
    "    last_token_eos = token == \"[EOS]\"\n",
    "\n",
    "prefix = prefix[:-6]   \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0db8c1",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "В качестве результата вы должны предоставить bleu вашей модели на тестовой выборке wmt14 и перевод 10 предложений с немецкого на английский."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cfa33baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|██▎       | 680/3003 [00:30<01:06, 35.12it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "test_data = wmt14[\"test\"][\"translation\"]\n",
    "preds = [\" \".join(get_last_token_prediction(\"\", x['de'], model, return_seq=True)[:len(x['de'])]) for x in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82a701bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_corpus = [\" \".join(tokenize_pipeline(x['en'])) for x in test_data]\n",
    "test_bleu = bleu.compute(references=reference_corpus, predictions=preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7e91dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_sentences = [\n",
    "    \"Gutach: Noch mehr Sicherheit für Fußgänger\",\n",
    "    \"Zwei Anlagen so nah beieinander: Absicht oder Schildbürgerstreich?\",\n",
    "    \"Dies bestätigt auch Peter Arnold vom Landratsamt Offenburg.\",\n",
    "    \"Daher sei der Bau einer weiteren Ampel mehr als notwendig: \\\"Sicherheit geht hier einfach vor\\\", so Arnold.\",\n",
    "    \"Pro Fahrtrichtung gibt es drei Lichtanlagen.\",\n",
    "    \"Drückt der Fußgänger den Ampelknopf, testet der obere Radarsensor die Verkehrslage.\",\n",
    "    \"Ein weiteres Radarsensor prüft, ob die Grünphase für den Fußgänger beendet werden kann.\",\n",
    "    \"Josef Winkler schreibt sich seit mehr als 30 Jahren die Nöte seiner Kindheit und Jugend von der Seele.\",\n",
    "    \"Dabei scheint Regisseur Fresacher dem Text wenig zu vertrauen.\",\n",
    "    \"Sie werden hart angefasst, mit dem Kopf unter Wasser getaucht, mit ihren Abendroben an die Wand getackert.\",\n",
    "]\n",
    "en_sentences = [\" \".join(get_last_token_prediction(\"\", x, model, return_seq=True)[:len(x)]) \n",
    "                for x in de_sentences] # get translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b29d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "submission = {\n",
    "    \"tasks\": [\n",
    "        {\"task1\": {\"answer\": test_bleu}},\n",
    "        {\"task2\": {\"answer\": en_sentences}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "yaml.safe_dump(submission, open(\"submission.yaml\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
