{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309ee2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb4001e40f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# preparetions of dataset\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f9689",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90004ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, trasform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.trasform = trasform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.trasform:\n",
    "            image = self.trasform(image)\n",
    "            image = torchvision.transforms.functional.rgb_to_grayscale(image, num_output_channels=3)\n",
    "            \n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1202c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8921, 2) (28762, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37683, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = ['./images/Blur_Positive_target//'+f for f in listdir('./images/Blur_Positive_target/') if isfile(join('./images/Blur_Positive_target', f))]\n",
    "\n",
    "dataset = pd.DataFrame(onlyfiles, columns=['path'])\n",
    "dataset['target'] = 1\n",
    "onlyfiles = ['./images/Blur_Empty_table/'+f for f in listdir('./images/Blur_Empty_table/') if isfile(join('./images/Blur_Empty_table/', f))]\n",
    "second = pd.DataFrame(onlyfiles, columns=['path'])\n",
    "second['target'] = 0\n",
    "print(dataset.shape, second.shape)\n",
    "finaldataset = pd.concat([dataset, second])\n",
    "\n",
    "finaldataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b2c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldataset.to_csv(\"Gray_Blured_Data.csv\", index=False)\n",
    "dataset = CreateDataset(csv_file='./Gray_Blured_Data.csv', root_dir='./',\n",
    "                       trasform=transforms.ToTensor())\n",
    "train, valid, test = torch.utils.data.random_split(dataset, [24494, 3768, 9421])\n",
    "train_loader = DataLoader(dataset=train, batch_size=24494, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=train, batch_size=3768, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=9421, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85de87ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24494, 3, 116, 116])\n",
      "Train:  x=torch.Size([24494, 3, 116, 116]) y=torch.Size([24494])\n",
      "Validation:  x=torch.Size([1886, 3, 116, 116]) y=torch.Size([1886])\n",
      "Test:  x=torch.Size([9421, 3, 116, 116]) y=torch.Size([9421])\n"
     ]
    }
   ],
   "source": [
    "for batch, (data, targets) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    X_train = data\n",
    "    y_train = targets\n",
    "print(f'Train:  x={X_train.shape} y={y_train.shape}')\n",
    "\n",
    "for batch, (data, targets) in enumerate(valid_loader):\n",
    "    X_valid = data\n",
    "    y_valid = targets\n",
    "print(f'Validation:  x={X_valid.shape} y={y_valid.shape}')\n",
    "    \n",
    "for batch, (data, targets) in enumerate(test_loader):\n",
    "    X_test = data\n",
    "    y_test = targets\n",
    "print(f'Test:  x={X_test.shape} y={y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deaab10",
   "metadata": {},
   "source": [
    "### Data to grayscale (shape = (1, 116, 116))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43977b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  torch.Size([24494, 1, 116, 116])\n",
      "Validation:  torch.Size([1886, 1, 116, 116])\n",
      "Test:  torch.Size([9421, 1, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "transform_to_gray = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "X_train = transform_to_gray(X_train)\n",
    "print('Train: ', X_train.shape)\n",
    "\n",
    "transform_to_gray = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "X_valid = transform_to_gray(X_valid)\n",
    "print('Validation: ', X_valid.shape)\n",
    "\n",
    "transform_to_gray = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "X_test = transform_to_gray(X_test)\n",
    "print('Test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4be585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy to tensor\n",
    "y_train = y_train.to(torch.float)\n",
    "y_valid = y_valid.to(torch.float)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571e29c",
   "metadata": {},
   "source": [
    "# Neural_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee20c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest model on Pytorch (there is no need in convolution)\n",
    "# MaxPool2d -> Linear -> Sigmoid\n",
    "class Revision(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Revision, self).__init__()\n",
    "        \n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(58*58, 1)\n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool2(x)\n",
    "        # растягиваем вектор х\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "final_v4 = Revision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2030e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(final_v4.parameters(), amsgrad=True, lr=0.001)\n",
    "loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79056086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9894)\n",
      "tensor(0.9915)\n",
      "tensor(0.9920)\n",
      "tensor(0.9920)\n",
      "tensor(0.9920)\n",
      "tensor(0.9958)\n",
      "tensor(0.9920)\n",
      "tensor(0.9958)\n",
      "tensor(0.9963)\n",
      "tensor(0.9947)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9947)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9968)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9968)\n",
      "tensor(0.9968)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9979)\n",
      "tensor(0.9984)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9984)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n",
      "tensor(0.9973)\n",
      "tensor(0.9979)\n",
      "tensor(0.9973)\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "batch_size = 100\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "for epoch in range(65):\n",
    "    # create batches\n",
    "    order = np.random.permutation(len(X_train))\n",
    "\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        # fit model\n",
    "        optimizer.zero_grad()\n",
    "        final_v4.train()\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "        X_batch = X_train[batch_indexes]\n",
    "        y_batch = y_train[batch_indexes]\n",
    "\n",
    "        preds = final_v4.forward(X_batch).squeeze()\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    # evaluate on valid data\n",
    "    final_v4.eval()\n",
    "    test_preds = final_v4.forward(X_valid).squeeze()\n",
    "    test_loss_history.append(loss(test_preds,y_valid).data)\n",
    "\n",
    "    accuracy = (torch.round(test_preds) == y_valid).float().mean().data\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    if accuracy == 0.9995:\n",
    "        break\n",
    "\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c56b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9983)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_v4.eval()\n",
    "test_preds = final_v4.forward(X_test).squeeze()\n",
    "accuracy = (torch.round(test_preds) == y_test).float().mean().data\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69ae9a",
   "metadata": {},
   "source": [
    "# Same, but on keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a29e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:05:06.596370: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-18 19:05:06.598309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 19:05:06.600971: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "X_train_tf = tf.constant(X_train.numpy(), dtype=tf.float16)\n",
    "X_test_tf = tf.constant(X_test.numpy(), dtype=tf.float16)\n",
    "y_test_tf = tf.constant(y_test.numpy(), dtype=tf.float16)\n",
    "y_train_tf = tf.constant(y_train.numpy(), dtype=tf.float16)\n",
    "X_valid_tf = tf.constant(X_valid.numpy(), dtype=tf.float16)\n",
    "y_valid_tf = tf.constant(y_valid.numpy(), dtype=tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d92d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(1, 116, 116)),\n",
    "    tf.keras.layers.Permute((2,3,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38eaaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 116, 116, 1)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 58, 58, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3364)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3365      \n",
      "=================================================================\n",
      "Total params: 3,365\n",
      "Trainable params: 3,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974d300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8fbe113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:05:08.821375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-12-18 19:05:08.848157: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1190400000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 11s 42ms/step - loss: 0.1673 - accuracy: 0.9289 - val_loss: 0.0384 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "245/245 [==============================] - 9s 39ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
      "Epoch 3/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.0276 - val_accuracy: 0.9931\n",
      "Epoch 4/40\n",
      "245/245 [==============================] - 11s 43ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0276 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.0271 - val_accuracy: 0.9920\n",
      "Epoch 6/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0228 - val_accuracy: 0.9942\n",
      "Epoch 7/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0301 - val_accuracy: 0.9910\n",
      "Epoch 8/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0189 - val_accuracy: 0.9968\n",
      "Epoch 9/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0236 - val_accuracy: 0.9963\n",
      "Epoch 10/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0166 - val_accuracy: 0.9968\n",
      "Epoch 11/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0164 - val_accuracy: 0.9968\n",
      "Epoch 12/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0145 - val_accuracy: 0.9968\n",
      "Epoch 13/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0138 - val_accuracy: 0.9979\n",
      "Epoch 14/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0130 - val_accuracy: 0.9973\n",
      "Epoch 15/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0133 - val_accuracy: 0.9979\n",
      "Epoch 16/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0114 - val_accuracy: 0.9973\n",
      "Epoch 17/40\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0132 - val_accuracy: 0.9968\n",
      "Epoch 18/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
      "Epoch 19/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0099 - val_accuracy: 0.9973\n",
      "Epoch 20/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0101 - val_accuracy: 0.9973\n",
      "Epoch 21/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 22/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 23/40\n",
      "245/245 [==============================] - 11s 43ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 24/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 25/40\n",
      "245/245 [==============================] - 10s 43ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0075 - val_accuracy: 0.9979\n",
      "Epoch 26/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 27/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 28/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
      "Epoch 29/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0070 - val_accuracy: 0.9973\n",
      "Epoch 30/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
      "Epoch 31/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
      "Epoch 32/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 33/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
      "Epoch 34/40\n",
      "245/245 [==============================] - 10s 43ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 35/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 36/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 37/40\n",
      "245/245 [==============================] - 10s 40ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 38/40\n",
      "245/245 [==============================] - 10s 41ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 39/40\n",
      "245/245 [==============================] - 10s 42ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "Epoch 40/40\n",
      "245/245 [==============================] - 10s 43ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_tf,\n",
    "    y_train_tf,\n",
    "    batch_size=100,\n",
    "    epochs= 40,\n",
    "    validation_data=(X_valid_tf, y_valid_tf)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb85597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch\n",
      "[[1.         0.99563161]\n",
      " [0.99563161 1.        ]]\n",
      "Tensorflow\n",
      "[[1.         0.99604904]\n",
      " [0.99604904 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "final_v4.eval()\n",
    "torch_preds = final_v4.forward(X_test).squeeze().detach().numpy()\n",
    "\n",
    "print(\"Pytorch\")\n",
    "print(np.corrcoef([torch_preds, y_test.numpy()]))\n",
    "\n",
    "\n",
    "tensorflow_preds = model.predict(X_test_tf).squeeze()\n",
    "print(\"Tensorflow\")\n",
    "print(np.corrcoef([tensorflow_preds, y_test.numpy()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
